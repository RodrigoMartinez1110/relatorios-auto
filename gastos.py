import pandas as pd
import streamlit as st
import gspread
from oauth2client.service_account import ServiceAccountCredentials

# Configura√ß√£o da p√°gina no Streamlit
st.set_page_config(page_title="Processador de Campanhas", layout="wide")
st.title("üìä Processador de Dados de Campanhas")

# Upload do arquivo CSV
uploaded_file = st.file_uploader("üìÇ Fa√ßa upload do arquivo CSV", type=["csv"])

if uploaded_file is not None:
    # Ler o arquivo CSV
    base = pd.read_csv(uploaded_file, sep=';', low_memory=False)

    # Dicion√°rio para normaliza√ß√£o dos conv√™nios
    mapeamento_convenios = {
        "GOV SP": ["governo de sp", "gov sp", "governo sp"],
        "GOV CE": ["gov ce", "ceara", "governo do ceara"],
        "GOV RJ": ["governo de rj", "gov rj", "governo rio"],
        "GOV AL": ["governo de al", "gov al", "governo alagoas"],
        "GOV AM": ["governo de am", "gov am", "governo amazonas"],
        "GOV ES": ["governo de es", "gov es", "governo esp√≠rito santo"],
        "GOV GO": ["governo de go", "gov go", "governo goi√°s"],
        "GOV MA": ["governo de ma", "gov ma", "governo maranh√£o"],
        "GOV MS": ["governo de ms", "gov ms", "governo mato grosso do sul"],
        "GOV MT": ["governo de mt", "gov mt", "governo mato grosso"],
        "GOV PE": ["governo de pe", "gov pe", "governo pernambuco"],
        "GOV PI": ["governo de pi", "gov pi", "governo piau√≠"],
        "GOV PR": ["governo de pr", "gov pr", "governo paran√°"],
        "PREF GYN": ["pref gyn", "pref goiania", "prefeitura de goi√¢nia"],
        "PREF JP": ["pref jp", "prefeitura de jo√£o pessoa"],
        "PREF MARINGA": ["pref maringa", "prefeitura de maring√°"],
        "PREF RECIFE": ["pref recife", "prefeitura de recife"],
        "PREF RJ": ["pref rj", "prefeitura do rio de janeiro"],
        "PREF SP": ["pref sp", "prefeitura de s√£o paulo"],
        "PREF SSA": ["pref ssa", "prefeitura de salvador"]
    }

    # Fun√ß√£o para normalizar os conv√™nios
    def normalizar_convenio(nome_campanha):
        if pd.notna(nome_campanha):
            nome_campanha = nome_campanha.lower().strip()
            for convenio, nomes_possiveis in mapeamento_convenios.items():
                if any(nome in nome_campanha for nome in nomes_possiveis):
                    return convenio
        return "outro"

    # Aplicar normaliza√ß√£o dos conv√™nios
    base["CONVENIO"] = base["NOME CAMPANHA"].apply(normalizar_convenio)

    # Dicion√°rio para normaliza√ß√£o dos produtos
    mapeamento_produto = {
        "NOVO": ["novo", "credito novo", "negativos", "tomador", "super", "hubspot", "resgate", "carteira", "menor50", "menor 50", "virada"],
        "BENEFICIO E CART√ÉO": ["cart√µes", "cartoes", "benef & cartao", "cart√µes consignados"],
        "CART√ÉO": ["cart√£o", "cartao", "consignado"],
        "BENEFICIO": ["benef", "beneficio", "complementar"],
        "NQB": ["nqb"]
    }

    # Fun√ß√£o para normalizar os produtos
    def normalizar_produto(nome_produto):
        if pd.notna(nome_produto):
            nome_produto = nome_produto.lower().strip()
            for produto, nomes_possiveis in mapeamento_produto.items():
                if any(nome in nome_produto for nome in nomes_possiveis):
                    return produto
        return "outro"

    # Aplicar normaliza√ß√£o dos produtos
    base["PRODUTO"] = base["NOME CAMPANHA"].apply(normalizar_produto)

    # Converter data/hora para datetime
    base['DATA/HORA DISPARO'] = pd.to_datetime(base['DATA/HORA DISPARO'], errors='coerce', dayfirst=True)

    # Criar colunas separadas para data e hor√°rio
    base['DATA DISPARO'] = base['DATA/HORA DISPARO'].dt.strftime("%d/%m/%Y")
    base['HORA DISPARO'] = base['DATA/HORA DISPARO'].dt.strftime("%H:%M")
    base['HORA DISPARO'] = base.groupby(['DATA DISPARO', 'CONVENIO', 'PRODUTO'])['HORA DISPARO'].transform('min')

    # Criar tabela agrupada
    tabela = base.groupby(['DATA DISPARO', 'HORA DISPARO', 'CONVENIO', 'PRODUTO'])['ID CAMPANHA'].size().reset_index(name='quantidade')
    tabela['canal'] = 'RCS'
    tabela['gasto'] = tabela['quantidade'] * 0.105

    # Exibir DataFrames no Streamlit
    st.subheader("üìã Base de Dados Formatada")
    st.dataframe(base)

    st.subheader("üìä Tabela Agrupada")
    st.dataframe(tabela)

    # Fun√ß√£o para enviar os dados para o Google Sheets
    def enviar_para_sheets(df):
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        creds = ServiceAccountCredentials.from_json_keyfile_name("credencial.json", scope)
        client = gspread.authorize(creds)

        # Abrir a planilha
        sheet = client.open("controle_disparos").sheet1  # Nome da planilha no Google Sheets


        # Obter os dados existentes
        existing = pd.DataFrame(sheet.get_all_records())

        # Descobrir a pr√≥xima linha vazia
        start_row = len(existing) + 2  # Pular cabe√ßalho e ir para a pr√≥xima linha vazia

        # Converter DataFrame para lista de listas e adicionar ao Google Sheets
        sheet.insert_rows(df.values.tolist(), row=start_row)

        st.success("‚úÖ Dados enviados para o Google Sheets!")

    # Bot√£o para enviar dados para o Google Sheets
    if st.button("üì§ Enviar para Google Sheets"):
        enviar_para_sheets(tabela)

    # Bot√£o para exportar os dados processados
    st.download_button(
        label="üì• Baixar Tabela Agrupada",
        data=tabela.to_csv(index=False, sep=';').encode('utf-8'),
        file_name="tabela_formatada.csv",
        mime="text/csv"
    )
